<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>tHDFSPut</title><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="bk-tdi-components-rg-en..html" title="Talend Components"><link rel="up" href="ch-bigdata.html" title="Chapter&nbsp;1.&nbsp;Big Data components"><link rel="prev" href="tHDFSProperties.html" title="tHDFSProperties"><link rel="next" href="tHDFSRename.html" title="tHDFSRename"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">tHDFSPut</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="tHDFSProperties.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;1.&nbsp;Big Data components</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="tHDFSRename.html">Next</a></td></tr></table><hr></div><div lang="EN" class="section" title="tHDFSPut"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="tHDFSPut"></a>tHDFSPut</h2></div></div></div><div class="mediaobject"><img src="../images/thdfsput_icon32_white.png"></div><div class="warning" title="Warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>
			<span class="emphasis"><em>This component will be available in the <span class="emphasis"><strong>Palette</strong></span> of the studio on the condition that you have subscribed to
				the relevant edition of <span class="emphasis"><em>Talend Big Data Studio</em></span>.</em></span>
		</p></div><div class="section" title="tHDFSPut properties"><div class="titlepage"><div><div><h3 class="title"><a name="d0e15746"></a>tHDFSPut properties</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Component family</strong></span>
							</p>
						</td><td valign="top">
							<p>Big Data / Hadoop</p>
						</td><td valign="top">&nbsp;</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Function</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSPut </strong></span>loads data into Hadoop
								distributed file system(HDFS).</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Purpose</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSPut </strong></span>connects to Hadoop
								distributed file system to load large-scale files into it with
								optimized performance.</p>
						</td></tr><tr><td valign="top">
							<span class="emphasis"><strong>Basic settings</strong></span>
						</td><td valign="top">
							<p>
		<span class="emphasis"><em>Use an existing connection</em></span>
	</p>
						</td><td valign="top">
							<p>Select this check box and in the <span class="emphasis"><strong>Component List</strong></span> click the
		HDFS connection component from which you want to reuse the connection details already
		defined.</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When a Job contains the parent Job and the child Job, <span class="emphasis"><strong>Component
				list</strong></span> presents only the connection components in the same Job level.</p></div>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><em>Version</em></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Distribution</em></span>
							</p>
						</td><td valign="top">
							<p>Select the product you are using as the Hadoop distribution from the drop-down list. </p>
							<p>The options in the list vary depending on the component you are using.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Hadoop version</em></span>
							</p>
						</td><td valign="top">
							<p>Select the version of the Hadoop distribution you are using.</p>
						</td></tr><tr><td>
							<p>&nbsp;<span class="emphasis"><em>Connection</em></span></p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>NameNode URI</em></span>
							</p>
						</td><td valign="top">
							<p>Type in the URI of the Hadoop NameNode.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>User name</em></span>
							</p>
						</td><td>
							<p>Enter the user authentication name of HDFS.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Group</em></span>
							</p>
						</td><td valign="top">
							<p>Enter the membership including the authentication user under which
		the HDFS instances were started. This field is available depending
		on the distribution you are using.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Use kerberos authentication</em></span>
							</p>
						</td><td valign="top">
							<p>If you are accessing the Hadoop cluster running with Kerberos security, select this check
		box, then, enter the Kerberos principal name for the NameNode in the field displayed. This
		enables you to use your user name to authenticate against the credentials stored in
		Kerberos.</p>
							<p>This check box is available depending on the Hadoop distribution you are connecting
		to.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>HDFS directory</em></span>
							</p>
						</td><td valign="top">
							<p>Browse to, or enter the directory in HDFS where the data you need to use is.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Local directory</em></span>
							</p>
						</td><td valign="top">
							<p>Local directory where are stored the files to be loaded into
								HDFS.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Overwrite file</em></span>
							</p>
						</td><td valign="top">
							<p>Options to overwrite or not the existing file with the new
								one.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Files</em></span>
							</p>
						</td><td valign="top">
							<p>In the <span class="emphasis"><strong>Files</strong></span> area, the fields to
								be completed are:</p>
							<p> - <span class="emphasis"><strong>File mask</strong></span>: type in the file
								name to be selected from the local directory. Regular expression is
								available.</p>
							<p> - <span class="emphasis"><strong>New name</strong></span>: give a new name to
								the loaded file.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Die on error</em></span>
							</p>
						</td><td valign="top">
							<p>This check box is selected by default. Clear the check box to skip
								the row on error and complete the process for error-free
								rows.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>tStatCatcher Statistics</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to collect log data at the component
								level.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Dynamic settings</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>Click the <span class="emphasis"><strong>[+]</strong></span> button to add a row in the table and fill
		the <span class="emphasis"><strong>Code</strong></span> field with a context variable to choose your HDFS
		connection dynamically from multiple connections planned in your Job. This feature is useful
		when you need to access files in different HDFS systems or different distributions,
		especially when you are working in an environment where you cannot change your Job settings,
		for example, when your Job has to be deployed and executed independent of <span class="emphasis"><strong>Talend</strong></span>
		Studio.</p>
							<p>The <span class="emphasis"><strong>Dynamic settings</strong></span> table is available only when the
			<span class="emphasis"><strong>Use an existing connection</strong></span> check box is selected in the
			<span class="emphasis"><strong>Basic settings</strong></span> view. When a dynamic parameter is
		defined, the <span class="emphasis"><strong>Component List</strong></span> box in the <span class="emphasis"><strong>Basic settings</strong></span> view becomes unusable. </p>
							<p>For more information on <span class="emphasis"><strong>Dynamic settings</strong></span> and context
		variables, see <span class="emphasis"><em>Talend Data Integration Studio User Guide</em></span>.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Usage</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>This component combines HDFS connection and data extraction, thus
								usually used as a single-component subjob but also possible as
								output or end object.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Prerequisites</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>The Hadoop distribution must be properly installed, so as to guarantee the interaction
		with the Studio.</p>
							<p>For example, if you need to connect to MapR from the Studio, ensure that you have installed
		the MapR client in the machine where the Studio is, and added the MapR client library to the
		PATH variable of that machine. For Windows, this library is <span class="emphasis"><em>lib\MapRClient.dll</em></span> in the MapR client jar file; without adding it, you may
		encounter the following error: <code class="code">no MapRClient in java.library.path</code>.</p>
							<p>For further information about how to install an Hadoop distribution, see the manuals
		corresponding to the Hadoop distribution you are using.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Limitations</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>JRE 1.6+ is required.</p>
						</td></tr></tbody></table></div><p>
			<span>&nbsp;</span>
		</p></div><div class="section" title="Related scenario"><div class="titlepage"><div><div><h3 class="title"><a name="d0e16186"></a>Related scenario</h3></div></div></div><p>For related scenario, see <a class="xref" href="tHDFSGet.html#Raa73387" title="Scenario: Computing data with Hadoop distributed file system">the section called &#8220;Scenario: Computing data with Hadoop distributed file system&#8221;</a>.</p></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="tHDFSProperties.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="ch-bigdata.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="tHDFSRename.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">tHDFSProperties&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="bk-tdi-components-rg-en..html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;tHDFSRename</td></tr></table></div></body></html>