<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>tHDFSOutput</title><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="bk-tdi-components-rg-en..html" title="Talend Components"><link rel="up" href="ch-bigdata.html" title="Chapter&nbsp;1.&nbsp;Big Data components"><link rel="prev" href="tHDFSList.html" title="tHDFSList"><link rel="next" href="tHDFSProperties.html" title="tHDFSProperties"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">tHDFSOutput</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="tHDFSList.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;1.&nbsp;Big Data components</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="tHDFSProperties.html">Next</a></td></tr></table><hr></div><div lang="EN" class="section" title="tHDFSOutput"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="tHDFSOutput"></a>tHDFSOutput</h2></div></div></div><div class="mediaobject"><img src="../images/thdfsoutput_icon32_white.png"></div><div class="warning" title="Warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>
			<span class="emphasis"><em>This component will be available in the <span class="emphasis"><strong>Palette</strong></span> of the studio on the condition that you have subscribed to
				the relevant edition of <span class="emphasis"><em>Talend Big Data Studio</em></span>.</em></span>
		</p></div><div class="section" title="tHDFSOutput properties"><div class="titlepage"><div><div><h3 class="title"><a name="d0e14422"></a>tHDFSOutput properties</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Component family</strong></span>
							</p>
						</td><td valign="top">
							<p>Big Data / Hadoop</p>
						</td><td valign="top">&nbsp;</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Function</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSOutput</strong></span> writes data flows it
								receives onto a given Hadoop distributed file system (HDFS). </p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Purpose</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSOnput</strong></span> writes data of
								interest into a file and creates this file on a given HDFS.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Basic settings</strong></span>
							</p>
						</td><td valign="top">
							<p><span class="emphasis"><em>Schema</em></span> and <span class="emphasis"><em>Edit
								Schema</em></span></p>
						</td><td valign="top">
							<p>A schema is a row description, i.e., it defines the number of fields to be processed and
		passed on to the next component. <span>The schema is either
				<span class="emphasis"><strong>Built-in</strong></span> or stored remotely in the <span class="emphasis"><strong>Repository</strong></span></span>.</p>
							<p>Click <span class="emphasis"><strong>Edit Schema</strong></span> to make changes to the schema. <span>Note that if you make changes, the schema automatically becomes
			built-in.</span></p>
							<p>If you are using <span class="emphasis"><em>Talend Open Studio for Big Data</em></span>, only the <span class="emphasis"><strong>Built-in</strong></span> mode is available.</p>
						</td></tr><tr><td valign="top">&nbsp;</td><td valign="top">&nbsp;</td><td valign="top">
							<p><span class="emphasis"><strong>Built-in</strong></span>: You create and store the schema locally for
		this component only. Related topic: see <span class="emphasis"><em>Talend Data Integration Studio</em></span>
		<span class="emphasis"><em>User Guide</em></span>.</p>
						</td></tr><tr><td valign="top">&nbsp;</td><td valign="top">&nbsp;</td><td valign="top">
							<p><span class="emphasis"><strong>Repository</strong></span>: You have already created the schema and
		stored it in the Repository. You can reuse it in various projects and Job designs. Related
		topic: see the user guide of the Studio for integration.</p>
						</td></tr><tr><td valign="top">&nbsp;</td><td valign="top">
							<p>
		<span class="emphasis"><em>Use an existing connection</em></span>
	</p>
						</td><td valign="top">
							<p>Select this check box and in the <span class="emphasis"><strong>Component List</strong></span> click the
		HDFS connection component from which you want to reuse the connection details already
		defined.</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When a Job contains the parent Job and the child Job, <span class="emphasis"><strong>Component
				list</strong></span> presents only the connection components in the same Job level, so if
			you need to use an existing connection from the other level, you can use <span class="emphasis"><strong>Dynamic settings</strong></span> to share the intended connection. In this
			case, ensure that the connection name is unique and distinctive all over through the two
			Job levels. For more information about <span class="emphasis"><strong>Dynamic
			settings</strong></span>, see <span class="emphasis"><em>Talend Data Integration Studio User Guide</em></span>.</p></div>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><em>Version</em></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Distribution</em></span>
							</p>
						</td><td valign="top">
							<p>Select the product you are using as the Hadoop distribution from the drop-down list. </p>
							<p>The options in the list vary depending on the component you are using.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Hadoop version</em></span>
							</p>
						</td><td valign="top">
							<p>Select the version of the Hadoop distribution you are using.</p>
						</td></tr><tr><td> </td><td valign="top">
							<p>
								<span class="emphasis"><em>NameNode URI</em></span>
							</p>
						</td><td valign="top">
							<p>Type in the URI of the Hadoop NameNode.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>User name</em></span>
							</p>
						</td><td>
							<p>Enter the user authentication name of HDFS.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Group</em></span>
							</p>
						</td><td valign="top">
							<p>Enter the membership including the authentication user under which
		the HDFS instances were started. This field is available depending
		on the distribution you are using.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Use kerberos authentication</em></span>
							</p>
						</td><td valign="top">
							<p>If you are accessing the Hadoop cluster running with Kerberos security, select this check
		box, then, enter the Kerberos principal name for the NameNode in the field displayed. This
		enables you to use your user name to authenticate against the credentials stored in
		Kerberos.</p>
							<p>This check box is available depending on the Hadoop distribution you are connecting
		to.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>File Name</em></span>
							</p>
						</td><td valign="top">
							<p>Browse to, or enter the location of the file which you write data
								to. This file is created automatically if it does not exist.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Action</em></span>
							</p>
						</td><td valign="top">
							<p>Select an operation in HDFS:</p>
							<p><span class="emphasis"><strong>Create</strong></span>: Creates a file with data
								using the file name defined in the <span class="emphasis"><strong>File
									Name</strong></span> field.</p>
							<p><span class="emphasis"><strong>Overwrite</strong></span>: Overwrites the data in
								the file specified in the <span class="emphasis"><strong>File Name</strong></span>
								field.</p>
							<p><span class="emphasis"><strong>Append</strong></span>: Inserts the data into the
								file specified in the <span class="emphasis"><strong>File Name</strong></span>
								field. The specified file is created automatically if it does not
								exist.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Row separator</em></span>
							</p>
						</td><td valign="top">
							<p>Enter the separator used to identify the end of a row.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Field separator</em></span>
							</p>
						</td><td valign="top">
							<p>Enter the separator used to identify the end of a field.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Encoding</em></span>
							</p>
						</td><td valign="top">
							<p>Select the encoding from the list or select <span class="emphasis"><strong>Custom</strong></span> and define it manually. This field is
		compulsory for DB data handling.</p>
						</td></tr><tr><td>
							<p>
								<span class="emphasis"><strong>Advanced settings</strong></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Hadoop properties</em></span>
							</p>
						</td><td valign="top">
							<p>If you need to use custom configuration for the Hadoop of
		interest, complete this table with the property or properties to be
		customized. Then at runtime, the customized property or properties
		will override those corresponding ones defined earlier for the same
		Hadoop. </p>
							<p>For further information about the properties required by Hadoop,
		see the Hadoop documentation. </p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>tStatCatcher Statistics</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to collect log data at the component
								level.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Usage</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>This component needs an input component.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Prerequisites</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>The Hadoop distribution must be properly installed, so as to guarantee the interaction
		with the Studio.</p>
							<p>For example, if you need to connect to MapR from the Studio, ensure that you have installed
		the MapR client in the machine where the Studio is, and added the MapR client library to the
		PATH variable of that machine. For Windows, this library is <span class="emphasis"><em>lib\MapRClient.dll</em></span> in the MapR client jar file; without adding it, you may
		encounter the following error: <code class="code">no MapRClient in java.library.path</code>.</p>
							<p>For further information about how to install an Hadoop distribution, see the manuals
		corresponding to the Hadoop distribution you are using.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Limitations</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>JRE 1.6+ is required.</p>
						</td></tr></tbody></table></div></div><div class="section" title="Related scenario"><div class="titlepage"><div><div><h3 class="title"><a name="d0e14906"></a>Related scenario</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Related topic, see <a class="xref" href="tFileOutputDelimited.html#ychen-20111116-file-tfileoutputdelimited_scenario" title="Scenario 1: Writing data in a delimited file">the section called &#8220;Scenario 1: Writing data in a delimited file&#8221;</a>.</p></li><li class="listitem"><p>Related topic, see <a class="xref" href="tHDFSGet.html#Raa73387" title="Scenario: Computing data with Hadoop distributed file system">the section called &#8220;Scenario: Computing data with Hadoop distributed file system&#8221;</a>.</p></li></ul></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="tHDFSList.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="ch-bigdata.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="tHDFSProperties.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">tHDFSList&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="bk-tdi-components-rg-en..html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;tHDFSProperties</td></tr></table></div></body></html>