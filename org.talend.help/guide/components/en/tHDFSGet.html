<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>tHDFSGet</title><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="bk-tdi-components-rg-en..html" title="Talend Components"><link rel="up" href="ch-bigdata.html" title="Chapter&nbsp;1.&nbsp;Big Data components"><link rel="prev" href="tHDFSExist.html" title="tHDFSExist"><link rel="next" href="tHDFSInput.html" title="tHDFSInput"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">tHDFSGet</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="tHDFSExist.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;1.&nbsp;Big Data components</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="tHDFSInput.html">Next</a></td></tr></table><hr></div><div lang="EN" class="section" title="tHDFSGet"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="tHDFSGet"></a>tHDFSGet</h2></div></div></div><div class="mediaobject"><img src="../images/thdfsget_icon32_white.png"></div><div class="warning" title="Warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>
			<span class="emphasis"><em>This component will be available in the <span class="emphasis"><strong>Palette</strong></span> of the studio on the condition that you have subscribed to
				the relevant edition of <span class="emphasis"><em>Talend Big Data Studio</em></span>.</em></span>
		</p></div><div class="section" title="tHDFSGet properties"><div class="titlepage"><div><div><h3 class="title"><a name="d0e12053"></a>tHDFSGet properties</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Component family</strong></span>
							</p>
						</td><td valign="top">
							<p>Big Data / Hadoop</p>
						</td><td valign="top">&nbsp;</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Function</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSGet </strong></span>gets data from Hadoop
								distributed file system(HDFS).</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Purpose</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tHDFSGet </strong></span>connects to Hadoop
								distributed file system, helping to obtain large-scale files with
								optimized performance.</p>
						</td></tr><tr><td valign="top">
							<span class="emphasis"><strong>Basic settings</strong></span>
						</td><td valign="top">
							<p>
		<span class="emphasis"><em>Use an existing connection</em></span>
	</p>
						</td><td valign="top">
							<p>Select this check box and in the <span class="emphasis"><strong>Component List</strong></span> click the
		HDFS connection component from which you want to reuse the connection details already
		defined.</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When a Job contains the parent Job and the child Job, <span class="emphasis"><strong>Component
				list</strong></span> presents only the connection components in the same Job level, so if
			you need to use an existing connection from the other level, you can use <span class="emphasis"><strong>Dynamic settings</strong></span> to share the intended connection. In this
			case, ensure that the connection name is unique and distinctive all over through the two
			Job levels. For more information about <span class="emphasis"><strong>Dynamic
			settings</strong></span>, see <span class="emphasis"><em>Talend Data Integration Studio User Guide</em></span>.</p></div>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><em>Version</em></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Distribution</em></span>
							</p>
						</td><td valign="top">
							<p>Select the product you are using as the Hadoop distribution from the drop-down list. </p>
							<p>The options in the list vary depending on the component you are using.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Hadoop version</em></span>
							</p>
						</td><td valign="top">
							<p>Select the version of the Hadoop distribution you are using.</p>
						</td></tr><tr><td>
							<p>&nbsp;<span class="emphasis"><em>Connection</em></span></p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>NameNode URI</em></span>
							</p>
						</td><td valign="top">
							<p>Type in the URI of the Hadoop NameNode.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>User name</em></span>
							</p>
						</td><td>
							<p>Enter the user authentication name of HDFS.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<p>
								<span class="emphasis"><em>Group</em></span>
							</p>
						</td><td valign="top">
							<p>Enter the membership including the authentication user under which
		the HDFS instances were started. This field is available depending
		on the distribution you are using.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Use kerberos authentication</em></span>
							</p>
						</td><td valign="top">
							<p>If you are accessing the Hadoop cluster running with Kerberos security, select this check
		box, then, enter the Kerberos principal name for the NameNode in the field displayed. This
		enables you to use your user name to authenticate against the credentials stored in
		Kerberos.</p>
							<p>This check box is available depending on the Hadoop distribution you are connecting
		to.</p>
						</td></tr><tr><td valign="top"> </td><td valign="top">
							<p>
								<span class="emphasis"><em>HDFS directory</em></span>
							</p>
						</td><td valign="top">
							<p>Browse to, or enter the directory in HDFS where the data you need to use is.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Local directory</em></span>
							</p>
						</td><td valign="top">
							<p>Browse to, or enter the local directory to store the files
								obtained from HDFS.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Overwrite file</em></span>
							</p>
						</td><td valign="top">
							<p>Options to overwrite or not the existing file with the new
								one.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Append</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to add the new rows at the end of the
								records</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Files</em></span>
							</p>
						</td><td valign="top">
							<p>In the <span class="emphasis"><strong>Files</strong></span> area, the fields to
								be completed are:</p>
							<p> - <span class="emphasis"><strong>File mask</strong></span>: type in the file
								name to be selected from HDFS. Regular expression is
								available.</p>
							<p> - <span class="emphasis"><strong>New name</strong></span>: give a new name to
								the obtained file. </p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Die on error</em></span>
							</p>
						</td><td valign="top">
							<p>This check box is selected by default. Clear the check box to skip
								the row on error and complete the process for error-free
								rows.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>tStatCatcher Statistics</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to collect log data at the component
								level.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Usage</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>This component combines HDFS connection and data extraction, thus
								used as a single-component subjob or to prepare data to feed the
								input flow of a Job. It is often connected to the Job using
									<span class="emphasis"><strong>OnSubJobOk</strong></span> or <span class="emphasis"><strong>OnComponentOk link</strong></span>, depending on the
								context.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Prerequisites</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>The Hadoop distribution must be properly installed, so as to guarantee the interaction
		with the Studio.</p>
							<p>For example, if you need to connect to MapR from the Studio, ensure that you have installed
		the MapR client in the machine where the Studio is, and added the MapR client library to the
		PATH variable of that machine. For Windows, this library is <span class="emphasis"><em>lib\MapRClient.dll</em></span> in the MapR client jar file; without adding it, you may
		encounter the following error: <code class="code">no MapRClient in java.library.path</code>.</p>
							<p>For further information about how to install an Hadoop distribution, see the manuals
		corresponding to the Hadoop distribution you are using.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Limitations</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>JRE 1.6+ is required.</p>
						</td></tr></tbody></table></div><p>
			<span>&nbsp;</span>
		</p></div><div class="section" title="Scenario: Computing data with Hadoop distributed file system"><div class="titlepage"><div><div><h3 class="title"><a name="Raa73387"></a>Scenario: Computing data with Hadoop distributed file system</h3></div></div></div><p>The following scenario describes a simple Job that creates a file in a defined
			directory, get it into and out of HDFS, subsequently store it to another local
			directory, and read it at the end of the Job.</p><div class="section" title="Setting up the Job"><div class="titlepage"><div><div><h4 class="title"><a name="d0e12479"></a>Setting up the Job</h4></div></div></div><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Drop the following components from the <span class="emphasis"><strong>Palette</strong></span> onto the design workspace: <span class="emphasis"><strong>tFixedFlowInput</strong></span>, <span class="emphasis"><strong>tFileOutputDelimited</strong></span>, <span class="emphasis"><strong>tHDFSPut</strong></span>, <span class="emphasis"><strong>tHDFSGet</strong></span>,
							<span class="emphasis"><strong>tFileInputDelimited</strong></span> and <span class="emphasis"><strong>tLogRow</strong></span>.</p></li><li class="step" title="Step 2"><p>Connect <span class="emphasis"><strong>tFixedFlowInput</strong></span> to <span class="emphasis"><strong>tFileOutputDelimited</strong></span> using a <span class="emphasis"><strong>Row</strong></span> &gt; <span class="emphasis"><strong>Main</strong></span>
						connection.</p></li><li class="step" title="Step 3"><p>Connect <span class="emphasis"><strong>tFileInputDelimited</strong></span> to <span class="emphasis"><strong>tLogRow</strong></span> using a <span class="emphasis"><strong>Row</strong></span> &gt; <span class="emphasis"><strong>Main</strong></span>
						connection.</p></li><li class="step" title="Step 4"><p>Connect <span class="emphasis"><strong>tFixedFlowInput</strong></span> to <span class="emphasis"><strong>tHDFSPut</strong></span> using an <span class="emphasis"><strong>OnSubjobOk</strong></span> connection.</p></li><li class="step" title="Step 5"><p>Connect <span class="emphasis"><strong>tHDFSPut</strong></span> to <span class="emphasis"><strong>tHDFSGet</strong></span> using an <span class="emphasis"><strong>OnSubjobOk</strong></span> connection.</p></li><li class="step" title="Step 6"><p>Connect <span class="emphasis"><strong>tHDFSGet</strong></span> to <span class="emphasis"><strong>tFileInputDelimited</strong></span>using an <span class="emphasis"><strong>OnSubjobOk</strong></span> connection.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet1.png"></div></li></ol></div></div><div class="section" title="Configuring the input component"><div class="titlepage"><div><div><h4 class="title"><a name="d0e12576"></a>Configuring the input component</h4></div></div></div><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click <span class="emphasis"><strong>tFixedFlowInput</strong></span> to define
						the component in its <span class="emphasis"><strong>Basic settings</strong></span>
						view.</p></li><li class="step" title="Step 2"><p>Set the <span class="emphasis"><strong>Schema </strong></span>to <span class="emphasis"><strong>Built-In</strong></span> and click the three-dot <span class="emphasis"><strong>[...]</strong></span> button next to <span class="emphasis"><strong>Edit
							Schema</strong></span> to describe the data structure you want to create from
						internal variables. In this scenario, the schema contains one column:
							<span class="emphasis"><em>content</em></span>.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet3.png"></div></li><li class="step" title="Step 3"><p>Click the plus button to add the parameter line.</p></li><li class="step" title="Step 4"><p>Click <span class="emphasis"><strong>OK</strong></span> to close the dialog box and
						accept to propagate the changes when prompted by the studio.</p></li><li class="step" title="Step 5"><p>In <span class="emphasis"><strong>Basic settings</strong></span>, define the
						corresponding value in the <span class="emphasis"><strong>Mode</strong></span> area using
						the <span class="emphasis"><strong>Use Single Table </strong></span>option. In this
						scenario, the value is <span class="emphasis"><em>&#8220;Hello world!&#8221;</em></span>.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet2.png"></div></li></ol></div></div><div class="section" title="Configuring the tFileOutputDelimited component"><div class="titlepage"><div><div><h4 class="title"><a name="d0e12637"></a>Configuring the tFileOutputDelimited component</h4></div></div></div><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click <span class="emphasis"><strong>tFileOutputDelimited</strong></span> to
						define the component in its <span class="emphasis"><strong>Basic settings</strong></span>
						view.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet4.png"></div></li><li class="step" title="Step 2"><p>Click the <span class="emphasis"><strong>[...]</strong></span> button next to the
							<span class="emphasis"><strong>File Name</strong></span> field and browse to the
						output file you want to write data in, <span class="emphasis"><em>in.txt</em></span> in this
						example.</p></li></ol></div></div><div class="section" title="Loading the data from the local file"><div class="titlepage"><div><div><h4 class="title"><a name="d0e12665"></a>Loading the data from the local file</h4></div></div></div><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click <span class="emphasis"><strong>tHDFSPut</strong></span> to define the
						component in its <span class="emphasis"><strong>Basic settings</strong></span>
						view.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet5.png"></div></li><li class="step" title="Step 2"><p>Select, for example, Apache 0.20.2 from the <span class="emphasis"><strong>Hadoop
							version</strong></span> list.</p></li><li class="step" title="Step 3"><p>In the <span class="emphasis"><strong>NameNode URI</strong></span>, the <span class="emphasis"><strong>Username</strong></span> and the <span class="emphasis"><strong>Group</strong></span> fields, enter the connection parameters to the
						HDFS.</p></li><li class="step" title="Step 4"><p>Next to the <span class="emphasis"><strong>Local directory</strong></span> field, click
						the three-dot <span class="emphasis"><strong>[...]</strong></span> button to browse to the
						folder with the file to be loaded into the HDFS. In this scenario, the
						directory has been specified while configuring <span class="emphasis"><strong>tFileOutputDelimited</strong></span>:
							<span class="emphasis"><em>C:/hadoopfiles/putFile/</em></span>. </p></li><li class="step" title="Step 5"><p>In the <span class="emphasis"><strong>HDFS directory</strong></span> field, type in the
						intended location in HDFS to store the file to be loaded. In this example,
						it is <span class="emphasis"><em>/testFile</em></span>.</p></li><li class="step" title="Step 6"><p>Click the <span class="emphasis"><strong>Overwrite file</strong></span> field to stretch
						the drop-down.</p></li><li class="step" title="Step 7"><p>From the menu, select <span class="emphasis"><strong>always</strong></span>.</p></li><li class="step" title="Step 8"><p>In the <span class="emphasis"><strong>Files</strong></span> area, click the plus button
						to add a row in which you define the file to be loaded.</p></li><li class="step" title="Step 9"><p>In the <span class="emphasis"><strong>File mask</strong></span> column, enter
							<span class="emphasis"><em>*.txt</em></span> to replace <span class="emphasis"><em>newLine</em></span>
						between quotation marks and leave the <span class="emphasis"><strong>New
							name</strong></span> column as it is. This allows you to extract all the
							<span class="emphasis"><em>.txt</em></span> files in the specified directory without
						changing their names. In this example, the file is<span class="emphasis"><em>
							in.txt</em></span>.</p></li></ol></div></div><div class="section" title="Getting the data from the HDFS"><div class="titlepage"><div><div><h4 class="title"><a name="d0e12762"></a>Getting the data from the HDFS</h4></div></div></div><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click <span class="emphasis"><strong>tHDFSGet</strong></span> to define the
						component in its <span class="emphasis"><strong>Basic settings</strong></span>
						view.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet6.png"></div></li><li class="step" title="Step 2"><p>Select, for example, Apache 0.20.2 from the <span class="emphasis"><strong>Hadoop
							version</strong></span> list.</p></li><li class="step" title="Step 3"><p>In the <span class="emphasis"><strong>NameNode URI</strong></span>, the <span class="emphasis"><strong>Username</strong></span>, the <span class="emphasis"><strong>Group</strong></span> fields, enter the connection parameters to the
						HDFS.</p></li><li class="step" title="Step 4"><p>In the <span class="emphasis"><strong>HDFS directory</strong></span> field, type in
						location storing the loaded file in HDFS. In this example, it is
							<span class="emphasis"><em>/testFile</em></span>.</p></li><li class="step" title="Step 5"><p>Next to the <span class="emphasis"><strong>Local directory</strong></span> field, click
						the three-dot <span class="emphasis"><strong>[...]</strong></span> button to browse to the
						folder intended to store the files that are extracted out of the HDFS. In
						this scenario, the directory is:
							<span class="emphasis"><em>C:/hadoopfiles/getFile/</em></span>. </p></li><li class="step" title="Step 6"><p>Click the <span class="emphasis"><strong>Overwrite file</strong></span> field to stretch
						the drop-down.</p></li><li class="step" title="Step 7"><p>From the menu, select <span class="emphasis"><strong>always</strong></span>.</p></li><li class="step" title="Step 8"><p>In the <span class="emphasis"><strong>Files</strong></span> area, click the plus button
						to add a row in which you define the file to be extracted.</p></li><li class="step" title="Step 9"><p>In the <span class="emphasis"><strong>File mask</strong></span> column, enter
							<span class="emphasis"><em>*.txt</em></span> to replace <span class="emphasis"><em>newLine</em></span>
						between quotation marks and leave the <span class="emphasis"><strong>New
							name</strong></span> column as it is. This allows you to extract all the
							<span class="emphasis"><em>.txt</em></span> files from the specified directory in the HDFS
						without changing their names. In this example, the file is<span class="emphasis"><em>
							in.txt</em></span>.</p></li></ol></div></div><div class="section" title="Reading data from the HDFS and saving the data locally"><div class="titlepage"><div><div><h4 class="title"><a name="d0e12856"></a>Reading data from the HDFS and saving the data locally</h4></div></div></div><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click <span class="emphasis"><strong>tFileInputDelimited</strong></span> to
						define the component in its <span class="emphasis"><strong>Basic settings</strong></span>
						view.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet7.png"></div></li><li class="step" title="Step 2"><p>Set property type to <span class="emphasis"><strong>Built-In</strong></span>.</p></li><li class="step" title="Step 3"><p>Next to the <span class="emphasis"><strong>File Name/Stream</strong></span> field, click
						the three-dot button to browse to the file you have obtained from the HDFS.
						In this scenario, the directory is
							<span class="emphasis"><em>C:/hadoopfiles/getFile/in.txt</em></span>.</p></li><li class="step" title="Step 4"><p>Set <span class="emphasis"><strong>Schema</strong></span> to <span class="emphasis"><strong>Built-In </strong></span>and click <span class="emphasis"><strong>Edit
							schema</strong></span> to define the data to pass on to the <span class="emphasis"><strong>tLogRow</strong></span> component. </p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet8.png"></div></li><li class="step" title="Step 5"><p>Click the plus button to add a new column.</p></li><li class="step" title="Step 6"><p>Click <span class="emphasis"><strong>OK</strong></span> to close the dialog box and
						accept to propagate the changes when prompted by the studio.</p></li></ol></div></div><div class="section" title="Executing the Job"><div class="titlepage"><div><div><h4 class="title"><a name="d0e12914"></a>Executing the Job</h4></div></div></div><p>Save the Job and press <span class="emphasis"><strong>F6</strong></span> to execute it.</p><p>The <span class="emphasis"><em>in.txt</em></span> file is created and loaded into the HDFS.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet9.png"></div><p>The file is also extracted from the HDFS by <span class="emphasis"><strong>tHDFSGet</strong></span> and is read by <span class="emphasis"><strong>tFileInputDelimited</strong></span>.</p><div class="mediaobject"><img src="../images/Use_Case_tHDFSGet10.png"></div></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="tHDFSExist.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="ch-bigdata.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="tHDFSInput.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">tHDFSExist&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="bk-tdi-components-rg-en..html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;tHDFSInput</td></tr></table></div></body></html>